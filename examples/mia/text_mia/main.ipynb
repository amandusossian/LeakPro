{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset and train a model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.append(project_root)\n",
    "from examples.mia.text_mia.utils.tabds_data_preparation import *\n",
    "from examples.mia.text_mia.utils.tabds_model_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local dataset\n",
      "Training\n",
      "Epoch 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n",
      "100%|██████████| 40/40 [00:18<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_datafolder = os.path.join(os.getcwd(), \"tab_data/\")\n",
    "dataset = preprocess_tab_dataset(path_to_datafolder, create_new=False)\n",
    "\n",
    "train_loader, test_loader = get_tab_dataloaders(dataset, train_fraction=0.1, \n",
    "test_fraction=0.1)\n",
    "\n",
    "### Generate target model \n",
    "\n",
    "if not os.path.exists(\"target\"):\n",
    "    os.makedirs(\"target\")\n",
    "\n",
    "\n",
    "n_classes = 3 # Case dependent, is equal to 2*number of masktypes + 1\n",
    "pretrained_model_name = \"allenai/longformer-base-4096\"\n",
    "model = TABBERT(pt_model= pretrained_model_name, num_classes=n_classes)\n",
    "n_epochs = 1\n",
    "\n",
    "\n",
    "train_acc, train_loss, test_acc, test_loss = create_trained_model_and_metadata(model = model, \n",
    "                                                                               train_loader = train_loader, \n",
    "                                                                               test_loader = test_loader, \n",
    "                                                                               epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LeakPro objects and run attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 09:19:25,329 INFO     Target model blueprint created from TABBERT in utils/tabds_model_preparation.py.\n",
      "2024-10-31 09:19:25,331 INFO     Loaded target model metadata from ./target/model_metadata.pkl\n",
      "/home/amandus/msc-code/LeakPro/leakpro/input_handler/handler_setup.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.target_model.load_state_dict(torch.load(f))\n",
      "2024-10-31 09:19:27,056 INFO     Loaded target model from ./target\n",
      "2024-10-31 09:19:31,617 INFO     Loaded population dataset from tab_data/tab_train_200_dataset.pkl\n",
      "2024-10-31 09:19:31,619 INFO     Loaded population dataset from tab_data/tab_train_200_dataset.pkl\n",
      "2024-10-31 09:19:31,619 INFO     Creating shadow model handler singleton\n",
      "2024-10-31 09:19:31,620 INFO     Creating distillation model handler singleton\n",
      "2024-10-31 09:19:31,622 INFO     Added attack: lira\n",
      "2024-10-31 09:19:31,623 INFO     Preparing attack: lira\n",
      "2024-10-31 09:19:31,624 INFO     Number of existing models exceeds or equals the number of models to create\n",
      "2024-10-31 09:19:31,624 INFO     Loading shadow model 0\n",
      "/home/amandus/msc-code/LeakPro/leakpro/attacks/utils/model_handler.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(load(f))\n",
      "2024-10-31 09:19:32,928 INFO     Loaded model from ./leakpro_output/attack_objects/shadow_model/shadow_model_0.pkl\n",
      "2024-10-31 09:19:32,929 INFO     Create masks for all IN and OUT samples\n",
      "2024-10-31 09:19:32,930 INFO     Loading metadata 0\n",
      "2024-10-31 09:19:32,972 INFO     Some shadow model(s) contains 33 IN samples in total for the model(s)\n",
      "2024-10-31 09:19:32,973 INFO     This is not an offline attack!\n",
      "2024-10-31 09:19:32,973 INFO     Calculating the logits for all 1 shadow models\n",
      "                                                                              \r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [2], [2, 4096]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/amandus/msc-code/LeakPro/examples/mia/text_mia/main.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.25.17.197/home/amandus/msc-code/LeakPro/examples/mia/text_mia/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m leakpro \u001b[39m=\u001b[39m LeakPro(TABInputHandler, config_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.25.17.197/home/amandus/msc-code/LeakPro/examples/mia/text_mia/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Run the audit \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.25.17.197/home/amandus/msc-code/LeakPro/examples/mia/text_mia/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m leakpro\u001b[39m.\u001b[39;49mrun_audit()\n",
      "File \u001b[0;32m~/msc-code/LeakPro/leakpro/leakpro.py:131\u001b[0m, in \u001b[0;36mLeakPro.run_audit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_audit\u001b[39m(\u001b[39mself\u001b[39m:Self) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the audit.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     audit_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattack_scheduler\u001b[39m.\u001b[39;49mrun_attacks()\n\u001b[1;32m    133\u001b[0m     \u001b[39mfor\u001b[39;00m attack_name \u001b[39min\u001b[39;00m audit_results:\n\u001b[1;32m    134\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreparing results for attack: \u001b[39m\u001b[39m{\u001b[39;00mattack_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/msc-code/LeakPro/leakpro/attacks/attack_scheduler.py:59\u001b[0m, in \u001b[0;36mAttackScheduler.run_attacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m attack, attack_type \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattacks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattack_list):\n\u001b[1;32m     58\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreparing attack: \u001b[39m\u001b[39m{\u001b[39;00mattack_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     attack\u001b[39m.\u001b[39;49mprepare_attack()\n\u001b[1;32m     61\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRunning attack: \u001b[39m\u001b[39m{\u001b[39;00mattack_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m     result \u001b[39m=\u001b[39m attack\u001b[39m.\u001b[39mrun_attack()\n",
      "File \u001b[0;32m~/msc-code/LeakPro/leakpro/attacks/mia_attacks/lira.py:164\u001b[0m, in \u001b[0;36mAttackLiRA.prepare_attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    163\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalculating the logits for all \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_shadow_models\u001b[39m}\u001b[39;00m\u001b[39m shadow models\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshadow_models_logits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mswapaxes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignal(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshadow_models, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandler, audit_data_indices,\\\n\u001b[1;32m    165\u001b[0m                                                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[39m# Calculate logits for the target model\u001b[39;00m\n\u001b[1;32m    168\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCalculating the logits for the target model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/msc-code/LeakPro/leakpro/signals/signal.py:132\u001b[0m, in \u001b[0;36mModelRescaledLogits.__call__\u001b[0;34m(self, models, handler, indices, batch_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m model_logits \u001b[39m=\u001b[39m []\n\u001b[1;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m data, labels \u001b[39min\u001b[39;00m tqdm(data_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetting rescaled logits for model \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/ \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(models)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    131\u001b[0m     \u001b[39m# Get logits for each data point\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mget_rescaled_logits(data,labels)\n\u001b[1;32m    133\u001b[0m     model_logits\u001b[39m.\u001b[39mextend(logits)\n\u001b[1;32m    134\u001b[0m model_logits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(model_logits)\n",
      "File \u001b[0;32m~/msc-code/LeakPro/leakpro/signals/signal_extractor.py:287\u001b[0m, in \u001b[0;36mPytorchModel.get_rescaled_logits\u001b[0;34m(self, batch_samples, batch_labels)\u001b[0m\n\u001b[1;32m    284\u001b[0m     predictions \u001b[39m=\u001b[39m predictions\u001b[39m/\u001b[39m\u001b[39msum\u001b[39m(predictions,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    286\u001b[0m count \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 287\u001b[0m y_true \u001b[39m=\u001b[39m predictions[np\u001b[39m.\u001b[39;49marange(count), y\u001b[39m.\u001b[39;49mtype(IntTensor)]\n\u001b[1;32m    288\u001b[0m predictions[np\u001b[39m.\u001b[39marange(count), y\u001b[39m.\u001b[39mtype(IntTensor)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    290\u001b[0m y_wrong \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(predictions, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [2], [2, 4096]"
     ]
    }
   ],
   "source": [
    "from tabds_handler import TABInputHandler\n",
    "\n",
    "from leakpro import LeakPro\n",
    "\n",
    "# Read the config file\n",
    "config_path = \"audit.yaml\"\n",
    "\n",
    "# Prepare leakpro object\n",
    "leakpro = LeakPro(TABInputHandler, config_path)\n",
    "\n",
    "# Run the audit \n",
    "leakpro.run_audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 13:06:53,308 INFO     Preparing attack: lira\n",
      "2024-10-30 13:47:29,015 INFO     Number of existing models exceeds or equals the number of models to create\n",
      "2024-10-30 13:48:00,664 INFO     Loading shadow model 0\n",
      "/home/amandus/msc-code/LeakPro/leakpro/attacks/utils/model_handler.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(load(f))\n",
      "2024-10-30 13:48:26,449 INFO     Loaded model from ./leakpro_output/attack_objects/shadow_model/shadow_model_0.pkl\n",
      "2024-10-30 13:49:30,954 INFO     Create masks for all IN and OUT samples\n",
      "2024-10-30 14:17:57,398 INFO     Loading metadata 0\n",
      "2024-10-30 14:33:52,244 INFO     Some shadow model(s) contains 40 IN samples in total for the model(s)\n",
      "2024-10-30 14:33:53,200 INFO     This is not an offline attack!\n",
      "2024-10-30 15:45:24,593 INFO     Calculating the logits for all 1 shadow models\n",
      "2024-10-30 15:46:11,586 INFO     Calculating the logits for the target model           \n",
      "2024-10-30 15:47:10,756 INFO     Running attack: lira                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_720175/2014151989.py\", line 1, in <module>\n",
      "    leakpro.run_audit()\n",
      "  File \"/home/amandus/msc-code/LeakPro/leakpro/leakpro.py\", line 131, in run_audit\n",
      "    audit_results = self.attack_scheduler.run_attacks()\n",
      "  File \"/home/amandus/msc-code/LeakPro/leakpro/attacks/attack_scheduler.py\", line 63, in run_attacks\n",
      "    result = attack.run_attack()\n",
      "  File \"/home/amandus/msc-code/LeakPro/leakpro/attacks/mia_attacks/lira.py\", line 266, in run_attack\n",
      "  File \"/home/amandus/msc-code/LeakPro/leakpro/attacks/mia_attacks/lira.py\", line 216, in get_std\n",
      "    # Fixed/Global variance calculation.\n",
      "  File \"/home/amandus/msc-code/LeakPro/leakpro/attacks/mia_attacks/lira.py\", line 232, in _fixed_variance\n",
      "    if is_in and not self.online:\n",
      "IndexError: boolean index did not match indexed array along dimension 0; dimension is 688956 but corresponding boolean dimension is 80\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/amandus/miniconda3/envs/leakpro/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "leakpro.run_audit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leakpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
